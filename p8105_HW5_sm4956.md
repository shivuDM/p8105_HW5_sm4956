p8105_hw5_sm4956
================
Shivangi Deepak Mewada

Loading the libraries required for the midterm, configuring the code
chunk dimensions, and creating themes and display for the plots for
knit.

## Problem 0

-   created repository and R project for HW5, created rmd file and
    rending to GitHub.
-   created a sub-directory/ data folder for the data set files to be
    used for this HW

``` r
library(tidyverse)
library(readxl)
library(dplyr)
library(ggridges)
library(tibble)
library(broom)
library(purrr)
options(tibble.print_min = 5)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Importing data in individual spreadsheets from data subdirectory. The
dataframe was created that includes list of all files in the directory.
map used to import data using `read_csv` function; and unnest used.

``` r
full_df = 
  tibble(
    files = list.files("data/zip_data/"),
    path = str_c("data/zip_data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest(cols = c(data))
```

Tidying the data, manipulating file names to include control arm and
subject ID, weekly observations tidied, with other data wrangling.

``` r
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)
```

Spaghetti plot to show observations on each subject over time, and
noting the trend

``` r
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```

<img src="p8105_HW5_sm4956_files/figure-gfm/unnamed-chunk-3-1.png" width="90%" />

This plot suggests high within-subject correlation – subjects who start
above average end up above average, and those that start below average
end up below average. Subjects in the control group generally don’t
change over time, but those in the experiment group increase their
outcome in a roughly linear way.

## Problem 2

Importing the raw homicides dataset:

``` r
homicide_raw_ds = read_csv(
    "data/homicide-data.csv") %>%
  janitor::clean_names()
```

Describing the raw Homicides dataset: - The total number of
observations/rows are **52179** and the total number of
variables/columns are **12** - This dataset has data on more than 52000
criminal homicides over the past decade in 50 of the largest American
cities.This included the location of the killing, whether an arrest was
made and, in most cases, basic demographic information about each
victim. - The key variables in this data set are **uid, reported_date,
victim_last, victim_first, victim_race, victim_age, victim_sex, city,
state, lat, lon, disposition**. Some key variables include names of the
homicide victims,their race, age, the cities and states these victims
belonged to, and information about the criminal disposition, i.e., if
there was no arrest, closed by arrest, or closed without arrest.

Data wrangling to create a city_state variable (e.g. “Baltimore, MD”),
summarizing within cities to obtain the total number of homicides and
the number of unsolved homicides (those for which the disposition is
“Closed without arrest” or “Open/No arrest”). Removing Tulsa_AL because
of the wrong combination of city and state.

``` r
homicide_ds = homicide_raw_ds %>%
unite('city_state',"city":"state", remove = FALSE)%>%
  select(-city,-state)%>%
   mutate (homi_type = case_when (disposition == "Closed without arrest" ~ "Unsolved", 
                                  disposition == "Open/No arrest" ~ "Unsolved", 
                                  disposition == "Closed by arrest" ~ "Solved" )) %>%
  group_by(city_state) %>%
  filter (city_state != "Tulsa_AL") %>%
  count(homi_type) %>%
  spread(key = homi_type, value = n)%>%
  mutate (total = Solved + Unsolved) %>%
  select (-Solved)
```

Filtering for Baltimore:

``` r
baltimore_homi = homicide_ds %>%
  filter(city_state == "Baltimore_MD")
```

Estimating Homicide proportion for Baltimore using prop.test and getting
estimate and 95% confidence intervals using broom::tidy

``` r
baltimore_proportion = 
  prop.test(baltimore_homi$Unsolved, baltimore_homi$total)%>%
  broom::tidy() %>%
  select (estimate, conf.low, conf.high)

  knitr::kable(baltimore_proportion)
```

|  estimate |  conf.low | conf.high |
|----------:|----------:|----------:|
| 0.6455607 | 0.6275625 | 0.6631599 |

Estimating Homicide proportion for each city using prop.test and getting
estimate and 95% confidence intervals using Tidy pipeline.

``` r
cities_proportion = homicide_ds %>%
  mutate(city_prop = list(broom::tidy(prop.test(Unsolved, total, conf.level=0.95)))) %>%
  unnest(city_prop)%>%
  select (city_state, estimate, conf.low, conf.high)%>%
  ungroup()
```

Plotting for the proportion estimate and 95% CI for each city, using
geom_errorbar to get the 95% CI on the plot, organizing the cities
according to the proportion of unsolved homicides in order.

``` r
plot_cities_prop = cities_proportion %>%
  mutate (city_state = reorder (city_state, estimate)) %>%
  ggplot(aes (x = city_state, y = estimate)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 60, hjust = 1)) + 
  labs (title = "Plot for proportion estimate with 95% CI for Cities and states",
        x = "City and State",
        y = "Proportion estimate with 95% CI")
  
plot_cities_prop
```

<img src="p8105_HW5_sm4956_files/figure-gfm/plotting proportions for cities-1.png" width="90%" />
